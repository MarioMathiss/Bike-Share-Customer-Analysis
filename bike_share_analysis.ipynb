{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and CSV Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONCAT Ride Trip Data Files (PRE Format A)\n",
    "os.chdir(FormatA_PATH)\n",
    "\n",
    "file_ext = \".csv\"\n",
    "all_file_names_pre = [i for i in glob.glob(f\"*{file_ext}\")]\n",
    "#df = pd.read_csv(all_file_names_pre[1])\n",
    "df_pre_A = pd.concat([pd.read_csv(file) for file in all_file_names_pre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONCAT Ride Trip Data Files (PRE Format B)\n",
    "os.chdir(FormatB_PATH)\n",
    "\n",
    "file_ext = \".csv\"\n",
    "all_file_names_pre = [i for i in glob.glob(f\"*{file_ext}\")]\n",
    "#df = pd.read_csv(all_file_names_pre[1])\n",
    "df_pre_B = pd.concat([pd.read_csv(file) for file in all_file_names_pre])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONCAT Ride Trip Data Files (POST)\n",
    "os.chdir(post_PATH)\n",
    "\n",
    "file_ext = \".csv\"\n",
    "all_file_names_post = [i for i in glob.glob(f\"*{file_ext}\")]\n",
    "#df = pd.read_csv(all_file_names_post[1])\n",
    "df_post = pd.concat([pd.read_csv(file) for file in all_file_names_post])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONCAT Station Data Files (Station)\n",
    "\n",
    "os.chdir(station_path)\n",
    "\n",
    "file_ext = \".csv\"\n",
    "all_file_names_station = [i for i in glob.glob(f\"*{file_ext}\")]\n",
    "#df = pd.read_csv(all_file_names_station[1])\n",
    "df_stations = pd.concat([pd.read_csv(file) for file in all_file_names_station])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat datetime columns 2014 - 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Start and stop time columns to datetime on the pre df [Jan 1, 2014 to Dec 31, 2017 formated differently]\n",
    "df_pre_B['start_time'] = pd.to_datetime(df_pre_B['start_time'])\n",
    "df_pre_B['starttime'] = pd.to_datetime(df_pre_B['starttime'])\n",
    "df_pre_B['stoptime'] = pd.to_datetime(df_pre_B['stoptime'])\n",
    "df_pre_B['end_time'] = pd.to_datetime(df_pre_B['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Format A and B to pre df\n",
    "df_pre = pd.concat([df_pre_A, df_pre_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Files to (pre, post, innner, outer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Start and end time\n",
    "# Merge of ride_start_time columns for PRE Dataframe (3 different column names, final column name: ride_start_time)\n",
    "df_pre['col1_start_time'] = df_pre['starttime'].where(df_pre['starttime'].notnull(), df_pre['start_time'])\n",
    "df_pre['ride_start_time'] = df_pre['col1_start_time'].where(df_pre['col1_start_time'].notnull(), df_pre['01 - Rental Details Local Start Time'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['starttime', 'start_time', '01 - Rental Details Local Start Time', 'col1_start_time'])\n",
    "\n",
    "# Merge of ride_stop_time columns for PRE Dataframe (3 different column names, final column name: ride_stop_time)\n",
    "df_pre['col1_end_time'] = df_pre['stoptime'].where(df_pre['stoptime'].notnull(), df_pre['end_time'])\n",
    "df_pre['ride_stop_time'] = df_pre['col1_end_time'].where(df_pre['col1_end_time'].notnull(), df_pre['01 - Rental Details Local End Time'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['stoptime', 'end_time', '01 - Rental Details Local End Time', 'col1_end_time'])\n",
    "\n",
    "## Mege Other Columns\n",
    "# Merge of ride_id columns for PRE Dataframe (2 different column names| final column name: (ride_id) and remove columns with null values\n",
    "df_pre['ride_id'] = df_pre['trip_id'].where(df_pre['trip_id'].notnull(), df_pre['01 - Rental Details Rental ID'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['trip_id', '01 - Rental Details Rental ID'])\n",
    "\n",
    "# Merge of bike_id columns for PRE Dataframe (2 different column names| final column name: (bike_id) and remove columns with null values\n",
    "df_pre['bike_id'] = df_pre['bikeid'].where(df_pre['bikeid'].notnull(), df_pre['01 - Rental Details Bike ID'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['bikeid', '01 - Rental Details Bike ID'])\n",
    "\n",
    "# Merge of from_station_id columns for PRE Dataframe (2 different column names| final column name: (from_station_id) and remove columns with null values\n",
    "df_pre['from_station_id'] = df_pre['from_station_id'].where(df_pre['from_station_id'].notnull(), df_pre['03 - Rental Start Station ID'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['03 - Rental Start Station ID'])\n",
    "\n",
    "# Merge of from_station_name columns for PRE Dataframe (2 different column names| final column name: (from_station_name) and remove columns with null values\n",
    "df_pre['from_station_name'] = df_pre['from_station_name'].where(df_pre['from_station_name'].notnull(), df_pre['03 - Rental Start Station Name'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['03 - Rental Start Station Name'])\n",
    "\n",
    "# Merge of to_station_id columns for PRE Dataframe (2 different column names| final column name: (to_station_id) and remove columns with null values\n",
    "df_pre['to_station_id'] = df_pre['to_station_id'].where(df_pre['to_station_id'].notnull(), df_pre['02 - Rental End Station ID'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['02 - Rental End Station ID'])\n",
    "\n",
    "# Merge of to_station_name columns for PRE Dataframe (2 different column names| final column name: (to_station_name) and remove columns with null values\n",
    "df_pre['to_station_name'] = df_pre['to_station_name'].where(df_pre['to_station_name'].notnull(), df_pre['02 - Rental End Station Name'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['02 - Rental End Station Name'])\n",
    "\n",
    "# Merge of user_type columns for PRE Dataframe (2 different column names| final column name: (user_type) and remove columns with null values\n",
    "df_pre['user_type'] = df_pre['usertype'].where(df_pre['usertype'].notnull(), df_pre['User Type'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['User Type', 'usertype'])\n",
    "\n",
    "# Merge of gender columns for PRE Dataframe (2 different column names| final column name: (gender) and remove columns with null values [high number of missing observations (5,004,980)]\n",
    "df_pre['gender'] = df_pre['gender'].where(df_pre['gender'].notnull(), df_pre['Member Gender'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['Member Gender'])\n",
    "\n",
    "# Merge of trip_time_s columns for PRE Dataframe (2 different column names| final column name: (trip_time_s) and remove columns with null values\n",
    "df_pre['trip_time_s'] = df_pre['tripduration'].where(df_pre['tripduration'].notnull(), df_pre['01 - Rental Details Duration In Seconds Uncapped'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['tripduration', '01 - Rental Details Duration In Seconds Uncapped'])\n",
    "\n",
    "# Merge of birth_year columns for PRE Dataframe (2 different column names| final column name: (birth_year) and remove columns with null values [high number of missing observations (4,976,997)]\n",
    "df_pre['birth_year_col1'] = df_pre['birthyear'].where(df_pre['birthyear'].notnull(), df_pre['birthday'])\n",
    "df_pre['birth_year'] = df_pre['birth_year_col1'].where(df_pre['birth_year_col1'].notnull(), df_pre['05 - Member Details Member Birthday Year'])\n",
    "\n",
    "df_pre = df_pre.drop(columns=['birth_year_col1', 'birthyear', 'birthday', '05 - Member Details Member Birthday Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename the member_casual column to usertype. AND rename member to Subscriber and casual to Customer \n",
    "df_post.rename(columns = {'member_casual':'user_type'}, inplace = True)\n",
    "\n",
    "df_post['user_type'] = df_post['user_type'].replace(['member'],'Subscriber')\n",
    "df_post['user_type'] = df_post['user_type'].replace(['casual'],'Customer')\n",
    "\n",
    "\n",
    "## Select only the data columns pre has in common with post, which we will later rename in order to merge\n",
    "# PRE:\n",
    "df_pre_common = df_pre[[\"ride_id\",\"ride_start_time\",\"ride_stop_time\",\"from_station_id\",\"from_station_name\",\"to_station_id\",\"to_station_name\",\"user_type\"]]\n",
    "# POST:\n",
    "df_post_common = df_post[[\"ride_id\",\"started_at\",\"ended_at\",\"start_station_id\",\"start_station_name\",\"end_station_id\",\"end_station_name\",\"user_type\"]]\n",
    "\n",
    "# Rename columns of POST to match those of PRE\n",
    "df_post_common.rename(columns = {'started_at':'ride_start_time', 'ended_at':'ride_stop_time', 'start_station_id':'from_station_id', 'start_station_name':'from_station_name', 'end_station_id':'to_station_id', 'end_station_name':'to_station_name'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN\n",
    "# Combine the two dataframes\n",
    "df_ride_trip_combined_inner = pd.concat([df_pre_common,df_post_common], ignore_index=True, sort=False)\n",
    "\n",
    "## Full JOIN\n",
    "# Rename columns in PRE to equivalent column in POST\n",
    "df_pre.rename(columns = {'trip_id':'ride_id', 'starttime':'started_at', 'stoptime':'ended_at', 'from_station_id':'start_station_id', 'from_station_name':'start_station_name', 'to_station_id':'end_station_id', 'to_station_name':'end_station_name'}, inplace = True)\n",
    "\n",
    "# Rename columns of POST to match those of PRE\n",
    "df_post_common.rename(columns = {'started_at':'ride_start_time', 'ended_at':'ride_stop_time', 'start_station_id':'from_station_id', 'start_station_name':'from_station_name', 'end_station_id':'to_station_id', 'end_station_name':'to_station_name','usertype':'user_type'}, inplace = True)\n",
    "\n",
    "df_ride_trip_combined_full = pd.concat([df_pre, df_post])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ridetrip_inner_MOD dataframe with calculated columns [created or edited]\n",
    "df_ridetrip_inner_MOD = df_ride_trip_combined_inner\n",
    "\n",
    "# CALCULATED COLUMNS:\n",
    "# New column ride_duration and ride_duration_s (Length of bike ride, regardless if negative time (indicating ride_start_time should be ride_stop_time ))\n",
    "df_ridetrip_inner_MOD[\"ride_duration\"] = (abs(pd.to_datetime(df_ridetrip_inner_MOD['ride_stop_time']).subtract(pd.to_datetime(df_ridetrip_inner_MOD['ride_start_time']))))\n",
    "df_ridetrip_inner_MOD['ride_duration_s'] = df_ridetrip_inner_MOD['ride_duration'].dt.seconds\n",
    "\n",
    "# new column same_station_trip (if the bike ride ended at the same station it started at)\n",
    "df_ridetrip_inner_MOD[\"same_station_trip\"] = (df_ridetrip_inner_MOD[\"from_station_id\"] == df_ridetrip_inner_MOD[\"to_station_id\"]).astype(int)\n",
    "\n",
    "# New ID column\n",
    "df_ridetrip_inner_MOD[\"ID\"] = df_ridetrip_inner_MOD.index + 1 \n",
    "\n",
    "# New Column with only the date (no time)\n",
    "df_ridetrip_inner_MOD['ride_start_date'] = pd.to_datetime(df_ridetrip_inner_MOD['ride_start_time']).dt.date\n",
    "\n",
    "## Export Dataframe with new columns to a new CSV \n",
    "#df_ridetrip_inner_MOD.to_csv(PATH\ride_trip_combined_inner_MOD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station Flow Dataframe creation\n",
    "df_station_flow_ALL = pd.DataFrame ()\n",
    "df_station_flow_ALL[\"flow\"] = (df_ridetrip_inner_MOD.groupby([\"to_station_name\"]).size() - df_ridetrip_inner_MOD.groupby([\"from_station_name\"]).size())\n",
    "\n",
    "# Filter data by user type\n",
    "df_customers = df_ridetrip_inner_MOD[df_ridetrip_inner_MOD['user_type'].str.contains(\"Customer\")]\n",
    "df_subscribers = df_ridetrip_inner_MOD[df_ridetrip_inner_MOD['user_type'].str.contains(\"Subscriber\")]\n",
    "\n",
    "# CUSTOMER Station Flow Dataframe creation\n",
    "station_flow_CUSTOMER = pd.DataFrame ()\n",
    "station_flow_CUSTOMER[\"flow\"] = (df_customers.groupby([\"to_station_name\"]).size() - df_customers.groupby([\"from_station_name\"]).size())\n",
    "\n",
    "# SUBSCRIBER Station Flow Dataframe creation\n",
    "station_flow_SUBSCRIBER = pd.DataFrame ()\n",
    "station_flow_SUBSCRIBER[\"flow\"] = (df_subscribers.groupby([\"to_station_name\"]).size() - df_subscribers.groupby([\"from_station_name\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frames: (Used for analysis in Tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export df to CSV file use -> [Example: df_pre.to_csv(PATH_TO_CSV_FILE)] \n",
    "df_pre\n",
    "df_post\n",
    "df_ride_trip_combined_inner\n",
    "df_ride_trip_combined_full\n",
    "df_station_flow_ALL\n",
    "station_flow_SUBSCRIBER\n",
    "station_flow_CUSTOMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ride_trip_combined_inner['ride_start_time'] = pd.to_datetime(df_ride_trip_combined_inner['ride_start_time'])\n",
    "df_ride_trip_combined_inner['ride_stop_time'] = pd.to_datetime(df_ride_trip_combined_inner['ride_stop_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ride_trip_combined_inner['ride_start_weekday_name'] = df_ride_trip_combined_inner['ride_start_time'].dt.day_name()\n",
    "\n",
    "df_ride_trip_combined_inner['ride_start_hour'] = df_ride_trip_combined_inner['ride_start_time'].dt.hour\n",
    "\n",
    "df_ride_trip_combined_inner['ride_start_month'] = df_ride_trip_combined_inner['ride_start_time'].dt.month\n",
    "\n",
    "df_ride_trip_combined_inner['ride_start_quarter'] = df_ride_trip_combined_inner['ride_start_time'].dt.quarter\n",
    "\n",
    "df_ride_trip_combined_inner['ride_start_year'] = df_ride_trip_combined_inner['ride_start_time'].dt.year\n",
    "\n",
    "df_ride_trip_combined_inner['ride_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subscribers = df_ride_trip_combined_inner[df_ride_trip_combined_inner['user_type'].str.contains(\"Subscriber\")]\n",
    "df_customers = df_ride_trip_combined_inner[df_ride_trip_combined_inner['user_type'].str.contains(\"Customer\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_type = df_ride_trip_combined_inner.pivot_table(index='user_type', values='ride_count', aggfunc='sum')\n",
    "fig = px.pie(df_user_type, values='ride_count', names=df_user_type.index)\n",
    "fig.update_layout(title_text='Ride Count % by User Type')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEATMAP Function\n",
    "def box_plot(df, Plot_Title):\n",
    "    date_year_hour = df.pivot_table(index='ride_start_hour', columns='ride_start_weekday_name', values='ride_count', aggfunc='sum')\n",
    "    date_year_hour = date_year_hour[['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']]\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "    sns.heatmap(date_year_hour, annot=False, fmt=\"d\", linewidths=.5, ax=ax).set(title= Plot_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df_ride_trip_combined_inner, \"All User Ride Count By Weekday and Time\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df_customers, \"Customer Ride Count By Weekday and Time\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df_subscribers, \"Subscriber Ride Count By Weekday and Time\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstb_usertype_by_hour = pd.crosstab(df_ride_trip_combined_inner['ride_start_hour'], df_ride_trip_combined_inner['user_type'])\n",
    "crosstb_usertype_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(crosstb_usertype_by_hour, x=crosstb_usertype_by_hour.index, y=crosstb_usertype_by_hour.columns, color=\"user_type\", line_group=\"user_type\", hover_name=\"user_type\",\n",
    "        line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.update_layout(title_text='Ride Count by Hour')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstb_usertype_by_year = pd.crosstab(df_ride_trip_combined_inner['ride_start_year'], df_ride_trip_combined_inner['user_type'])\n",
    "pl = crosstb_usertype_by_year.plot(kind=\"bar\", stacked=True, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstb_usertype_by_month = pd.crosstab(df_ride_trip_combined_inner['ride_start_month'], df_ride_trip_combined_inner['user_type'])\n",
    "pl = crosstb_usertype_by_month.plot(kind=\"bar\", stacked=True, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Station Flows\n",
    "df_station_flow_ALL = df_station_flow_ALL.dropna()\n",
    "print(\"Top Positive Flow:\\n\", df_station_flow_ALL.sort_values(by='flow', ascending= False).head(10))\n",
    "print(\"\\nTop Negative Flow:\\n\", df_station_flow_ALL.sort_values(by='flow', ascending= False).tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Freq Stations\n",
    "df_ridetrip_inner_MOD['start_end_station_names_combined'] = df_ridetrip_inner_MOD['from_station_name'] + \" | \" + df_ridetrip_inner_MOD['to_station_name']\n",
    "print(\"Most Frequest Station Combinations:\\n\", df_ridetrip_inner_MOD.groupby(by='start_end_station_names_combined').sum()['ride_count'].sort_values(ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4c2d24f1a70946ebf0a615fa60408bf5d82172403199ac915d708450a80ecc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
